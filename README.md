# Interpretable Machine Learning for Credit Risk Modeling using SHAP and LIME

This project builds an **interpretable machine learning pipeline** to predict **loan default risk** using an anonymized financial dataset (HELOC dataset).  
The primary focus is not only on model accuracy but also on **explainability**, using **SHAP** and **LIME** for transparent credit decision-making.

---

## ğŸ“Œ Key Objectives

1. Build a robust ML model to classify applicants as **Good** or **Bad** credit risk.  
2. Apply **SHAP** for global and local interpretability:
   - Summary plots
   - Feature contributions
   - Waterfall & force plots  
3. Apply **LIME** to validate instance-level explanations.  
4. Compare SHAP vs LIME and interpret results for **loan officers** and **regulatory compliance**.  
5. Save all SHAP/LIME visualizations automatically.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ data/
â”‚   â””â”€â”€ heloc_dataset.csv
â”œâ”€â”€ shap_plots/
â”‚   â”œâ”€â”€ shap_summary_plot.png
â”‚   â”œâ”€â”€ shap_waterfall_instance0.png
â”‚   â”œâ”€â”€ shap_feature_importance.png
â”‚   â””â”€â”€ shap_dependence_*.png
â”œâ”€â”€ lime_plots/
â”‚   â”œâ”€â”€ lime_explanation_instance0.png
â”‚   â””â”€â”€ lime_instance_*.png
â”œâ”€â”€ credit_risk_model.py
â””â”€â”€ README.md
```

---

## ğŸ§  Dataset Description

The HELOC dataset contains:
- Credit bureau scores  
- Transaction summary data  
- Payment behaviours  
- Delinquency history  
- RiskPerformance label (Good = 1, Bad = 0)

Special missing values like **-7** and **-8** are treated as `NaN`.

---

## ğŸš€ Modeling Steps

### 1. Data Preprocessing
- Encode target (Good â†’ 1, Bad â†’ 0)
- Replace special missing values and fill using median
- Train/test split

### 2. Models Trained
The following models were evaluated:

| Model | Purpose |
|-------|----------|
| Random Forest | Baseline ensemble |
| Gradient Boosting | Stable boosting model |
| XGBoost | High performance boosting |
| LightGBM | Fast, scalable boosting |

Each model is evaluated by:
- Test accuracy  
- **5-fold Cross-validation accuracy**

The model with the highest CV accuracy becomes the **best model**.

---

## ğŸ“Š Feature Importance

The top 10 most important features from the best model are printed along with a SHAP bar plot.  
These features usually represent:
- Credit utilization  
- Delinquency months  
- Number of satisfactory trades  
- Inquiry counts  
- Revolving credit behavior

---

## ğŸ” Explainability

### âœ” SHAP (SHapley Additive exPlanations)
Used for:
- **Global importance**  
- **Local explanation for each applicant**  
- **Regulatory-grade interpretability**

Plots generated:
- Summary plot  
- Feature importance bar plot  
- Waterfall plot  
- Force plot  
- Top-5 SHAP dependence plots  

### âœ” LIME (Local Interpretable Model-Agnostic Explanation)
Used to validate SHAPâ€™s local explanations.  
Plots are saved for the first 10 test instances.

---

## ğŸ†š SHAP vs LIME Summary

| Aspect | SHAP | LIME |
|--------|-------|-------|
| Nature | Game-theory exact | Local approximation |
| Consistency | Guaranteed | Not guaranteed |
| Best for | Regulatory, fairness audits | Debugging individual cases |
| Speed | Slower | Faster |
| Explanation type | Additive contributions | Local linear model |

---

## ğŸ“ Automatic Saving of Plots

All plots are saved automatically into:

```
shap_plots/
lime_plots/
```

This includes:
- SHAP summary
- SHAP waterfall
- SHAP force
- SHAP dependence
- LIME instance-wise plots

---

## ğŸ§ª How to Run

```bash
pip install -r requirements.txt
python credit_risk_model.py
```

---

## âœ… Requirements

```
pandas
numpy
scikit-learn
xgboost
lightgbm
lime
shap
matplotlib
```

Install them via:

```bash
pip install pandas numpy scikit-learn xgboost lightgbm lime shap matplotlib
```

---

## ğŸ“˜ Interpretation for Loan Officers

âœ” Identify why an applicant was classified as **Good** or **Bad**  
âœ” See which financial behaviours contributed positively or negatively  
âœ” Use explanations to support **fair & transparent** lending decisions  
âœ” Comply with **AI fairness and regulatory norms**

---

## ğŸ“Œ Final Outcome

This project provides:
- A complete ML pipeline  
- Deep interpretability using SHAP & LIME  
- Automated visualization export  
- A framework suitable for:
  - Research  
  - Banking applications  
  - Audit reporting  
  - Academic submissions  

---

## ğŸ“ Contact
Maintained by **Srinithinarayanan**  
For guidance or improvements, feel free to reach out!

---
